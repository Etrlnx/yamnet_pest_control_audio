{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":9784239,"datasetId":5994572,"databundleVersionId":10027403}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Install dependencies\n#!pip install -q tensorflow tensorflow_hub tensorflow_io kaggle\n\n#Importing necessary modules\nfrom google.colab import files\nimport zipfile\nimport pandas as pd\nimport os\nfrom google.colab import files\n\n#Preprocessing modules:\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport pickle\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\n\n#Model modules:\nimport librosa\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport soundfile as sf\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\n#Evaulation metrics:\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport warnings\nfrom sklearn.preprocessing import LabelEncoder\n\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T05:53:40.671114Z","iopub.execute_input":"2026-02-27T05:53:40.671422Z","iopub.status.idle":"2026-02-27T05:53:40.721997Z","shell.execute_reply.started":"2026-02-27T05:53:40.671398Z","shell.execute_reply":"2026-02-27T05:53:40.720867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generating the labelled csv file since the dataset does not come with one:\n\n\nwav_dir = \"/kaggle/input/insectsound1000/InsectSound1000\"\n\n\nspecies_to_category = {\n    \"Palomena_prasina\": \"pest\",\n    \"Nezara_viridula\": \"pest\",\n    \"Halyomorpha_halys\": \"pest\",\n    \"Rhaphigaster_nebulos\": \"pest\",\n    \"Bradysia_difformis\": \"pest\",\n    \"Myzus_persicae\": \"pest\",\n    \"Trialeurodes_vaporariorum\": \"pest\",\n    \"Tuta_absoluta\": \"pest\",\n\n    \"Bombus_terrestris\": \"beneficial\",\n    \"Episyrphus_balteatus\": \"beneficial\",\n    \"Coccinella_septempunctata\": \"beneficial\",\n    \"Aphidoletes_aphidimyza\": \"beneficial\"\n}\n\ndata = []\n\nfor filename in os.listdir(wav_dir):\n    if filename.endswith(\".wav\"):\n        parts = filename.split(\"_\")\n\n        if len(parts) >= 3:\n            species = parts[1] + \"_\" + parts[2]\n\n            if species in species_to_category:\n                category = species_to_category[species]\n\n                full_path = os.path.join(wav_dir, filename)\n\n                data.append({\n                    \"filepath\": full_path,\n                    \"species\": species,\n                    \"category\": category\n                })\n\ndf = pd.DataFrame(data)\n\ncsv_path = \"/kaggle/working/insect_labels_binary.csv\"\ndf.to_csv(csv_path, index=False)\n\nprint(\"CSV saved at:\", csv_path)\nprint(\"Total samples:\", len(df))\nprint(\"\\nCategory distribution:\\n\")\n\n#Converting \"category\" column to binary values for easy processing\n\ndf[\"category\"] = df[\"category\"].map({\n    \"pest\": 0,\n    \"beneficial\": 1\n})\n\n#Displaying the category value spread\nprint(df[\"category\"].value_counts())\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T05:53:40.724524Z","iopub.execute_input":"2026-02-27T05:53:40.725559Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Label file\nmetadata = pd.read_csv(\"/kaggle/working/insect_labels_binary.csv\")\nmetadata.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Directory verification\nfp = \"/kaggle/input/insectsound1000/InsectSound1000\"\naudio = os.listdir(fp)\nprint(f\"Total files: \",len(audio))\nprint(\"Sample files: \", audio[:5])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Downsampling the pest data to minimize data imbalance\n\n# Count samples per class\nprint(\"Before downsampling:\")\nprint(df[\"category\"].value_counts())\n\n# Separate pest and beneficial\npest_df = df[df[\"category\"] == 0]          # pests\nbeneficial_df = df[df[\"category\"] == 1]    # beneficials\n\n# Downsample pest to match beneficial count\npest_downsampled = pest_df.sample(\n    n=len(beneficial_df), \n    random_state=42\n)\n\n# Combine back into a balanced dataset\nbalanced_df = pd.concat([pest_downsampled, beneficial_df])\n\n# Shuffle rows\nbalanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n\nprint(\"After downsampling:\")\nprint(balanced_df[\"category\"].value_counts())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extracting labels and filepaths\n\nX = []\ny = []\n\nspecies_to_category = {\n    \"Palomena_prasina\": 0,\n    \"Nezara_viridula\": 0,\n    \"Halyomorpha_halys\": 0,\n    \"Rhaphigaster_nebulos\": 0,\n    \"Bradysia_difformis\": 0,\n    \"Myzus_persicae\": 0,\n    \"Trialeurodes_vaporariorum\": 0,\n    \"Tuta_absoluta\": 0,\n\n    \"Bombus_terrestris\": 1,\n    \"Episyrphus_balteatus\": 1,\n    \"Coccinella_septempunctata\": 1,\n    \"Aphidoletes_aphidimyza\": 1\n}\n\n\nX = balanced_df['filepath'].values;\ny = balanced_df['category'].values;\n\nprint(\"Total files:\", len(X))\nprint(\"Example:\", X[0], \"→\", y[0])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Verification of sampling rate to make sure it says as 16k\n\n\nfile_path = X[0]  # first audio file\n_, sr = librosa.load(file_path, sr=None)\n\nprint(\"Sampling rate:\", sr)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Encoding labels for compatability with model\n\n\nle = LabelEncoder()\ny_encoded = le.fit_transform(y)\n\nnum_classes = len(le.classes_)\n\nprint(\"Number of classes:\", num_classes)\nprint(\"Encoded example:\", y_encoded[:5])\nprint(\"Class mapping:\")\nfor i, cls in enumerate(le.classes_):\n    print(i, \"→\", cls)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Initializing to NumPy arrays for better performance\nX = np.array(X)\ny_encoded = np.array(y_encoded)\nprint(X[:5],\"\\n\",y_encoded[:5])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to load audio waveform from each file \n\n\n\ndef load_mono_py(file_path):\n    if isinstance(file_path, tf.Tensor):\n        file_path = file_path.numpy()\n    if isinstance(file_path, (bytes, bytearray)):\n        file_path = file_path.decode(\"utf-8\")\n    if isinstance(file_path, np.ndarray) and np.issubdtype(file_path.dtype, np.floating):\n        return file_path.astype(np.float32)\n    if isinstance(file_path, str):\n        data, sr = sf.read(file_path)\n        if len(data.shape) > 1:\n            data = np.mean(data, axis=1)\n        if sr != 16000:\n            data = librosa.resample(data, orig_sr=sr, target_sr=16000)\n        return data.astype(np.float32)\n    raise ValueError(f\"Unsupported type: {type(file_path)}\")\n\ndef load_mono_tf(file_path):\n    waveform = tf.py_function(\n        load_mono_py,\n        [file_path],\n        tf.float32\n    )\n    waveform.set_shape([None])  \n    return waveform\n\n\nyamnet = hub.load('https://tfhub.dev/google/yamnet/1')\n\n# Program to extract the relevant embeddings from the waveforms in the previous fn\n\n\ndef extembed(file_path, label):\n    waveform = load_mono_tf(file_path)\n    \n    scores, embeddings, spectrogram = yamnet(waveform)\n    mean = tf.reduce_mean(embeddings, axis=0)\n    std  = tf.math.reduce_std(embeddings, axis=0)\n    embedding = tf.concat([mean, std], axis=0)\n\n    # # Average temporal embeddings\n    # mean = tf.reduce_mean(embeddings, axis=0) \n    # #emean = tf.reduce_max(embeddings, axis=0) #In case mean does not work\n    # std = tf.math.reduce_std(embeddings, axis=0)\n    # embedding = tf.concat([mean, std], axis=0)\n\n    return embedding, label\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num = len(set(y_encoded))\n\nAUTOTUNE = tf.data.AUTOTUNE\n\ndataset = tf.data.Dataset.from_tensor_slices((X, y_encoded)) # Converts arrays into TensorFlow datasets\n\ndataset = (\n    dataset\n    .shuffle(10000)\n    .map(extembed, num_parallel_calls=AUTOTUNE)\n    .cache()\n    .batch(512)\n    .prefetch(AUTOTUNE)\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Classification phase: Dense NN\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n#Main dataset split\nX_train, X_val, y_train, y_val = train_test_split(\n    X,\n    y_encoded,\n    test_size=0.2,\n    stratify=y_encoded,\n    random_state=42\n)\n\n#Training and validation datasets:\ntrain_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\nval_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n\nAUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = (\n    train_ds\n    .shuffle(10000)\n    .map(extembed, num_parallel_calls=AUTOTUNE)\n    .batch(512)\n    .prefetch(AUTOTUNE)\n)\n\nval_ds = (\n    val_ds\n    .map(extembed, num_parallel_calls=AUTOTUNE)\n    .batch(512)\n    .prefetch(AUTOTUNE)\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CNN Architecture\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=(2048,)),   # matches pooled embedding\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for x_batch, y_batch in train_ds.take(1):\n    print(x_batch.shape, y_batch.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Code to handle class imbalance\nfrom sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\n\nclasses = np.unique(y_train)\n\nclass_weights = compute_class_weight(\n    class_weight=\"balanced\",\n    classes=classes,\n    y=y_train\n)\n\nclass_weight_dict = dict(zip(classes, class_weights))\ncount = 0;\nfor k,v in class_weight_dict.items():\n    print(\"Key: \",k,\"\\n\",\"Value: \",v)\n    count += 1;\n    if count > 5: break;","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(y_train[:5])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nmodel.summary()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Adding callbacks - Why?\ncallbacks = [\n    tf.keras.callbacks.EarlyStopping(\n        monitor=\"val_loss\",\n        patience=3,\n        restore_best_weights=True\n    ),\n    tf.keras.callbacks.ModelCheckpoint(\n        \"best_model.h5\",\n        save_best_only=True\n    )\n]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import soundfile as sf\n\n# for f in X[:1000]:\n#     try:\n#         info = sf.info(f)\n#         print(f\"{f}: channels={info.channels}, subtype={info.subtype}\")\n#     except Exception as e:\n#         print(f\"Corrupt or unreadable: {f} ({e})\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" #Model Training\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=5,\n    class_weight=class_weight_dict,\n    callbacks=callbacks\n)\n\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Model evaluation\nval_loss, val_acc = model.evaluate(val_ds)\nprint(\"Validation Accuracy:\", val_acc)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Classification report\n\ny_true = []\ny_pred = []\n\nfor embeddings, labels in val_ds:\n    preds = model.predict(embeddings)\n    y_true.extend(labels.numpy())\n    y_pred.extend((preds > 0.5).astype(\"int32\").flatten())\n\nprint(classification_report(y_true, y_pred))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Confusion matrix\ncm = confusion_matrix(y_val, y_pred)\ncls = le.classes_\nlabels = np.unique(np.concatenate((y_val, y_pred)))\ncomb = [cls[i] for i in labels]\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=comb, yticklabels=comb)\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# <u>Re-Training Model with Noisy Data:</u> ","metadata":{}},{"cell_type":"code","source":"\n# Function to add noise to dataset\ndef add_noise(waveform, noise_factor=0.005):\n    noise = tf.random.normal(shape=tf.shape(waveform), mean=0.0, stddev=1.0)\n    return waveform + noise_factor * noise","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to add noise while extracting embeddings\ndef extembed_noisy(file_path, label):\n    waveform = load_mono_tf(file_path)\n    waveform_noisy = add_noise(waveform)  # inject noise\n    scores, embeddings, spectrogram = yamnet(waveform_noisy)\n\n\n    mean = tf.reduce_mean(embeddings, axis=0)\n    std  = tf.math.reduce_std(embeddings, axis=0)\n    embedding = tf.concat([mean, std], axis=0)\n    return embedding, label\n\n\nnoisy_val_ds = (tf.data.Dataset.from_tensor_slices((X_val, y_val))\n    .map(extembed_noisy, num_parallel_calls=tf.data.AUTOTUNE)\n    .batch(512)\n    .prefetch(tf.data.AUTOTUNE)\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CNN Architecture\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=(2048,)),  \n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model compilation\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" #Model Training\nhistory = model.fit(\n    train_ds,\n    validation_data=noisy_val_ds,\n    epochs=5,\n    class_weight=class_weight_dict,\n    callbacks=callbacks\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model Evaluation\nloss, acc = model.evaluate(noisy_val_ds)\nprint(f\"Noisy test set accuracy: {acc:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Confusion matrix of the noisy data\n\n\ny_true = []\ny_pred = []\n\nfor x_batch, y_batch in noisy_val_ds:\n    preds = model.predict(x_batch)\n    preds = (preds > 0.5).astype(\"int32\")\n    y_true.extend(y_batch.numpy())\n    y_pred.extend(preds.flatten())\n\nprint(confusion_matrix(y_true, y_pred))\nprint(classification_report(y_true, y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# <u>Re-Training model after using noise reduction techniques</u> ","metadata":{}},{"cell_type":"markdown","source":" <u> Noise reduction technique:</u> Band-Pass filtering<br>\n\n Band-Pass filtering is a method of noise filtering where only there relevant frequency range is kept and the extra frequencies (noise) are normalized/attenuated.<br>\n Helps in removing unwanted hisses, static, bass, hum, etc that happens when operating under real world conditions.","metadata":{}},{"cell_type":"code","source":"\n\n# Function to implement band-pass filtering\ndef bandpass_filter(waveform, sr=16000, low=200, high=8000):\n    stft = librosa.stft(waveform.numpy()) # Short term Fourier transforms\n    freqs = librosa.fft_frequencies(sr=sr, n_fft=stft.shape[0]*2-1)\n\n    # Mask frequencies outside desired band\n    mask = (freqs >= low) & (freqs <= high)\n    stft_filtered = stft[mask, :]\n\n    # Inverse transform back to waveform\n    filtered = librosa.istft(stft_filtered)\n    return tf.convert_to_tensor(filtered, dtype=tf.float32)\n\n# Function to extract embeddings from the model after applying bnd pass filtering\ndef extembed_filtered(file_path, label):\n    waveform = load_mono_tf(file_path)\n    waveform_filtered = tf.py_function(\n        func=lambda x: bandpass_filter(x, sr=16000),\n        inp=[waveform],\n        Tout=tf.float32\n    )\n    waveform_filtered.set_shape([None])\n\n    # Pass filtered waveform into YAMNet\n    scores, embeddings, spectrogram = yamnet(waveform_filtered)\n\n    # Pool embeddings into fixed vector\n    mean = tf.reduce_mean(embeddings, axis=0)\n    std  = tf.math.reduce_std(embeddings, axis=0)\n    embedding = tf.concat([mean, std], axis=0)\n\n    return embedding, label\n\n# Build noisy+filtered validation dataset\nval_ds_filtered = (tf.data.Dataset.from_tensor_slices((X_val, y_val))\n    .map(extembed_filtered, num_parallel_calls=tf.data.AUTOTUNE)\n    .batch(512)\n    .prefetch(tf.data.AUTOTUNE)\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CNN Architecture\nmodel3 = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=(2048,)),   \n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model compilation\nmodel3.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nmodel3.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" #Model Training\nhistory = model3.fit(\n    train_ds,\n    validation_data=val_ds_filtered,\n    epochs=5,\n    class_weight=class_weight_dict,\n    callbacks=callbacks\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model Evaluation\nloss, acc = model.evaluate(val_ds_filtered)\nprint(f\"Filtered noisy validation accuracy: {acc:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Confusion matrix\n# Confusion matrix of the noisy data\n\n\ny_true = []\ny_pred = []\n\nfor x_batch, y_batch in val_ds_filtered:\n    preds = model.predict(x_batch)\n    preds = (preds > 0.5).astype(\"int32\")\n    y_true.extend(y_batch.numpy())\n    y_pred.extend(preds.flatten())\n\nprint(confusion_matrix(y_true, y_pred))\nprint(classification_report(y_true, y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}