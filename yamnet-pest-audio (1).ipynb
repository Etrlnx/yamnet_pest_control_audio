{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":9784239,"datasetId":5994572,"databundleVersionId":10027403}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-23T04:49:09.357683Z","iopub.execute_input":"2026-02-23T04:49:09.357926Z","iopub.status.idle":"2026-02-23T04:49:10.595579Z","shell.execute_reply.started":"2026-02-23T04:49:09.357899Z","shell.execute_reply":"2026-02-23T04:49:10.594697Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"#Install dependencies\n#!pip install -q tensorflow tensorflow_hub tensorflow_io kaggle\n\n#Importing necessary modules\nfrom google.colab import files\nimport zipfile\nimport pandas as pd\nimport os\nfrom google.colab import files\n\n#Preprocessing modules:\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport pickle\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\n\n#Model modules:\nimport librosa\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\n#Evaulation metrics:\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T04:49:10.598684Z","iopub.execute_input":"2026-02-23T04:49:10.599234Z","iopub.status.idle":"2026-02-23T04:49:33.167202Z","shell.execute_reply.started":"2026-02-23T04:49:10.599188Z","shell.execute_reply":"2026-02-23T04:49:33.166447Z"}},"outputs":[{"name":"stderr","text":"2026-02-23 04:49:14.730648: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1771822154.941941      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1771822155.006462      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1771822155.486138      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771822155.486181      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771822155.486185      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771822155.486188      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Generating the labelled csv file since the dataset does not come with one:\nimport os\nimport pandas as pd\n\nwav_dir = \"/kaggle/input/insectsound1000/InsectSound1000\"\n\n\nspecies_to_category = {\n    \"Palomena_prasina\": \"pest\",\n    \"Nezara_viridula\": \"pest\",\n    \"Halyomorpha_halys\": \"pest\",\n    \"Rhaphigaster_nebulos\": \"pest\",\n    \"Bradysia_difformis\": \"pest\",\n    \"Myzus_persicae\": \"pest\",\n    \"Trialeurodes_vaporariorum\": \"pest\",\n    \"Tuta_absoluta\": \"pest\",\n\n    \"Bombus_terrestris\": \"beneficial\",\n    \"Episyrphus_balteatus\": \"beneficial\",\n    \"Coccinella_septempunctata\": \"beneficial\",\n    \"Aphidoletes_aphidimyza\": \"beneficial\"\n}\n\ndata = []\n\nfor filename in os.listdir(wav_dir):\n    if filename.endswith(\".wav\"):\n        parts = filename.split(\"_\")\n\n        if len(parts) >= 3:\n            species = parts[1] + \"_\" + parts[2]\n\n            if species in species_to_category:\n                category = species_to_category[species]\n\n                full_path = os.path.join(wav_dir, filename)\n\n                data.append({\n                    \"filepath\": full_path,\n                    \"label\": species,\n                    \"category\": category\n                })\n\ndf = pd.DataFrame(data)\n\ncsv_path = \"/kaggle/working/insect_labels_binary.csv\"\ndf.to_csv(csv_path, index=False)\n\nprint(\"CSV saved at:\", csv_path)\nprint(\"Total samples:\", len(df))\nprint(\"\\nCategory distribution:\\n\")\n\n#Converting \"category\" column to binary values for easy processing\n\ndf[\"category\"] = df[\"category\"].map({\n    \"pest\": 0,\n    \"beneficial\": 1\n})\n\n#Displaying the category value spread\nprint(df[\"category\"].value_counts())\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T04:49:33.168342Z","iopub.execute_input":"2026-02-23T04:49:33.169015Z","iopub.status.idle":"2026-02-23T04:49:38.455886Z","shell.execute_reply.started":"2026-02-23T04:49:33.168975Z","shell.execute_reply":"2026-02-23T04:49:38.454931Z"}},"outputs":[{"name":"stdout","text":"CSV saved at: /kaggle/working/insect_labels_binary.csv\nTotal samples: 165982\n\nCategory distribution:\n\ncategory\n0    102076\n1     63906\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Label file\nmetadata = pd.read_csv(\"/kaggle/working/insect_labels_binary.csv\")\nmetadata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T04:49:38.457156Z","iopub.execute_input":"2026-02-23T04:49:38.457567Z","iopub.status.idle":"2026-02-23T04:49:38.851001Z","shell.execute_reply.started":"2026-02-23T04:49:38.457539Z","shell.execute_reply":"2026-02-23T04:49:38.850189Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                            filepath                 label  \\\n0  /kaggle/input/insectsound1000/InsectSound1000/...  Episyrphus_balteatus   \n1  /kaggle/input/insectsound1000/InsectSound1000/...     Halyomorpha_halys   \n2  /kaggle/input/insectsound1000/InsectSound1000/...       Nezara_viridula   \n3  /kaggle/input/insectsound1000/InsectSound1000/...       Nezara_viridula   \n4  /kaggle/input/insectsound1000/InsectSound1000/...    Bradysia_difformis   \n\n     category  \n0  beneficial  \n1        pest  \n2        pest  \n3        pest  \n4        pest  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filepath</th>\n      <th>label</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/insectsound1000/InsectSound1000/...</td>\n      <td>Episyrphus_balteatus</td>\n      <td>beneficial</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/insectsound1000/InsectSound1000/...</td>\n      <td>Halyomorpha_halys</td>\n      <td>pest</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/insectsound1000/InsectSound1000/...</td>\n      <td>Nezara_viridula</td>\n      <td>pest</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/insectsound1000/InsectSound1000/...</td>\n      <td>Nezara_viridula</td>\n      <td>pest</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/insectsound1000/InsectSound1000/...</td>\n      <td>Bradysia_difformis</td>\n      <td>pest</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"#Directory verification\nfp = \"/kaggle/input/insectsound1000/InsectSound1000\"\naudio = os.listdir(fp)\nprint(f\"Total files: \",len(audio))\nprint(\"Sample files: \", audio[:5])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T04:49:38.852086Z","iopub.execute_input":"2026-02-23T04:49:38.852345Z","iopub.status.idle":"2026-02-23T04:49:42.447759Z","shell.execute_reply.started":"2026-02-23T04:49:38.852322Z","shell.execute_reply":"2026-02-23T04:49:42.446824Z"}},"outputs":[{"name":"stdout","text":"Total files:  165982\nSample files:  ['2023613-16-37_Episyrphus_balteatus_000064_s71_ch0.wav', '2022524-16-36_Halyomorpha_halys_000038_s48_ch0.wav', '2022512-17-17_Nezara_viridula_000056_s2_ch0.wav', '202268-16-20_Nezara_viridula_000030_s15_ch0.wav', '2022329-13-41_Bradysia_difformis_000021_s13_ch0.wav']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Extracting labels and filepaths\n\nX = []\ny = []\n\nspecies_to_category = {\n    \"Palomena_prasina\": 0,\n    \"Nezara_viridula\": 0,\n    \"Halyomorpha_halys\": 0,\n    \"Rhaphigaster_nebulos\": 0,\n    \"Bradysia_difformis\": 0,\n    \"Myzus_persicae\": 0,\n    \"Trialeurodes_vaporariorum\": 0,\n    \"Tuta_absoluta\": 0,\n\n    \"Bombus_terrestris\": 1,\n    \"Episyrphus_balteatus\": 1,\n    \"Coccinella_septempunctata\": 1,\n    \"Aphidoletes_aphidimyza\": 1\n}\n\nfor filename in os.listdir(wav_dir):\n    if filename.endswith(\".wav\"):\n        parts = filename.split(\"_\")\n\n        if len(parts) >= 3:\n            species = parts[1] + \"_\" + parts[2]\n\n            if species in species_to_category:\n                full_path = os.path.join(wav_dir, filename)\n\n                X.append(full_path)\n                y.append(species_to_category[species])\n\nprint(\"Total files:\", len(X))\nprint(\"Example:\", X[0], \"→\", y[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T04:49:42.448863Z","iopub.execute_input":"2026-02-23T04:49:42.449179Z","iopub.status.idle":"2026-02-23T04:49:46.056024Z","shell.execute_reply.started":"2026-02-23T04:49:42.449148Z","shell.execute_reply":"2026-02-23T04:49:46.055052Z"}},"outputs":[{"name":"stdout","text":"Total files: 165982\nExample: /kaggle/input/insectsound1000/InsectSound1000/2023613-16-37_Episyrphus_balteatus_000064_s71_ch0.wav → 1\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Verification of sampling rate to make sure it says as 16k\nimport librosa\n\nfile_path = X[0]  # first audio file\n_, sr = librosa.load(file_path, sr=None)\n\nprint(\"Sampling rate:\", sr)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T04:49:46.058313Z","iopub.execute_input":"2026-02-23T04:49:46.058662Z","iopub.status.idle":"2026-02-23T04:50:01.948035Z","shell.execute_reply.started":"2026-02-23T04:49:46.058610Z","shell.execute_reply":"2026-02-23T04:50:01.947122Z"}},"outputs":[{"name":"stdout","text":"Sampling rate: 16000\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Encoding labels for compatability with model\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ny_encoded = le.fit_transform(y)\n\nnum_classes = len(le.classes_)\n\nprint(\"Number of classes:\", num_classes)\nprint(\"Encoded example:\", y_encoded[:5])\nprint(\"Class mapping:\")\nfor i, cls in enumerate(le.classes_):\n    print(i, \"→\", cls)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T04:50:01.948864Z","iopub.execute_input":"2026-02-23T04:50:01.949370Z","iopub.status.idle":"2026-02-23T04:50:01.978945Z","shell.execute_reply.started":"2026-02-23T04:50:01.949345Z","shell.execute_reply":"2026-02-23T04:50:01.977883Z"}},"outputs":[{"name":"stdout","text":"Number of classes: 2\nEncoded example: [1 0 0 0 0]\nClass mapping:\n0 → 0\n1 → 1\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"#Initializing to NumPy arrays for better performance\nX = np.array(X)\ny_encoded = np.array(y_encoded)\nprint(X[:5],\"\\n\",y_encoded[:5])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T04:50:01.980182Z","iopub.execute_input":"2026-02-23T04:50:01.980439Z","iopub.status.idle":"2026-02-23T04:50:02.084724Z","shell.execute_reply.started":"2026-02-23T04:50:01.980416Z","shell.execute_reply":"2026-02-23T04:50:02.083744Z"}},"outputs":[{"name":"stdout","text":"['/kaggle/input/insectsound1000/InsectSound1000/2023613-16-37_Episyrphus_balteatus_000064_s71_ch0.wav'\n '/kaggle/input/insectsound1000/InsectSound1000/2022524-16-36_Halyomorpha_halys_000038_s48_ch0.wav'\n '/kaggle/input/insectsound1000/InsectSound1000/2022512-17-17_Nezara_viridula_000056_s2_ch0.wav'\n '/kaggle/input/insectsound1000/InsectSound1000/202268-16-20_Nezara_viridula_000030_s15_ch0.wav'\n '/kaggle/input/insectsound1000/InsectSound1000/2022329-13-41_Bradysia_difformis_000021_s13_ch0.wav'] \n [1 0 0 0 0]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Function to load audio waveform from each file \n\nimport soundfile as sf\nimport tensorflow as tf\nimport numpy as np\n\ndef load_mono_py(file_path):\n    file_path = file_path.numpy().decode(\"utf-8\")\n    data, sr = sf.read(file_path)\n\n    if len(data.shape) > 1:\n        data = np.mean(data, axis=1)\n    if sr != 16000:\n        data = librosa.resample(data, orig_sr = sr, target_sr = 16000);\n\n    return data.astype(np.float32)\n\ndef load_mono_tf(file_path):\n    waveform = tf.py_function(\n        load_mono_py,\n        [file_path],\n        tf.float32\n    )\n    waveform.set_shape([None])  \n    return waveform\n\n\nyamnet = hub.load('https://tfhub.dev/google/yamnet/1')\n\n# Program to extract the relevant embeddings from the waveforms in the previous fn\n\n\ndef extembed(file_path, label):\n    waveform = load_mono_tf(file_path)\n    \n    scores, embeddings, spectrogram = yamnet(waveform)\n    embedding = embeddings\n\n    # # Average temporal embeddings\n    # mean = tf.reduce_mean(embeddings, axis=0) \n    # #emean = tf.reduce_max(embeddings, axis=0) #In case mean does not work\n    # std = tf.math.reduce_std(embeddings, axis=0)\n    # embedding = tf.concat([mean, std], axis=0)\n\n    return embedding, label\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num = len(set(y_encoded))\n\nAUTOTUNE = tf.data.AUTOTUNE\n\ndataset = tf.data.Dataset.from_tensor_slices((X, y_encoded)) # Converts arrays into TensorFlow datasets\n\ndataset = (\n    dataset\n    .shuffle(10000)\n    .map(extembed, num_parallel_calls=AUTOTUNE)\n    .cache()\n    .batch(512)\n    .prefetch(AUTOTUNE)\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Classification phase: Dense NN\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n#Main dataset split\nX_train, X_val, y_train, y_val = train_test_split(\n    X,\n    y_encoded,\n    test_size=0.2,\n    stratify=y_encoded,\n    random_state=42\n)\n\n#Standardizing inputs to improve performance:\n\n# scaler = StandardScaler()\n# X_train = scaler.fit_transform(X_train)\n# X_val = scaler.transform(X_val)\n\n\n#Training and validation datasets:\ntrain_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\nval_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n\nAUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = (\n    train_ds\n    .shuffle(10000)\n    .map(extembed, num_parallel_calls=AUTOTUNE)\n    .batch(512)\n    .prefetch(AUTOTUNE)\n)\n\nval_ds = (\n    val_ds\n    .map(extembed, num_parallel_calls=AUTOTUNE)\n    .batch(512)\n    .prefetch(AUTOTUNE)\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CNN Architecture\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=(None, 1024)),\n\n    tf.keras.layers.Conv1D(512, 3, padding='same', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv1D(256, 3, padding='same', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv1D(128, 3, padding='same', activation='relu'),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Code to handle class imbalance\nfrom sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\n\nclasses = np.unique(y_train)\n\nclass_weights = compute_class_weight(\n    class_weight=\"balanced\",\n    classes=classes,\n    y=y_train\n)\n\nclass_weight_dict = dict(zip(classes, class_weights))\ncount = 0;\nfor k,v in class_weight_dict.items():\n    print(\"Key: \",k,\"\\n\",\"Value: \",v)\n    count += 1;\n    if count > 5: break;","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(y_train[:5])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nmodel.summary()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Adding callbacks - Why?\ncallbacks = [\n    tf.keras.callbacks.EarlyStopping(\n        monitor=\"val_loss\",\n        patience=3,\n        restore_best_weights=True\n    ),\n    tf.keras.callbacks.ModelCheckpoint(\n        \"best_model.h5\",\n        save_best_only=True\n    )\n]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import soundfile as sf\n\n# for f in X[:1000]:\n#     try:\n#         info = sf.info(f)\n#         print(f\"{f}: channels={info.channels}, subtype={info.subtype}\")\n#     except Exception as e:\n#         print(f\"Corrupt or unreadable: {f} ({e})\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" #Model Training\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=5,\n    class_weight=class_weight_dict,\n    callbacks=callbacks\n)\n\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Model evaluation\nval_loss, val_acc = model.evaluate(val_ds)\nprint(\"Validation Accuracy:\", val_acc)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nimport numpy as np\n\ny_true = []\ny_pred = []\n\nfor embeddings, labels in val_ds:\n    preds = model.predict(embeddings)\n    y_true.extend(labels.numpy())\n    y_pred.extend(np.argmax(preds, axis=1))\n\nprint(classification_report(y_true, y_pred))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cm = confusion_matrix(y_val, y_pred)\ncls = le.classes_\nlabels = np.unique(np.concatenate((y_val, y_pred)))\ncomb = [cls[i] for i in labels]\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=comb, yticklabels=comb)\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the saved model and label encoder\nwith open(\"yamnet_rf_model.pkl\", \"rb\") as f:\n    mod = pickle.load(f)\n\nwith open(\"label_encoder.pkl\", \"rb\") as f:\n    le = pickle.load(f)\n\ndef pred_sound(file_path):\n\n    wf = audioprep(file_path)\n    embed = extembed(wf)\n    embed = embed.reshape(1, -1)\n    predicted_encoded = mod.predict(embed)\n    predicted_label = le.inverse_transform(predicted_encoded)\n    return predicted_label[0]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Re-initializing dataset with noise:","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}